# ファイルシステムのベンチマークを行う際に注意することとは?
という視点で次の論文を読みます:
https://www.fsl.cs.sunysb.edu/docs/fsbench/fsbench.pdf

# 0. 概要
* ファイルシステムやストレージシステムのベンチマークによる比較は難しい 
     * システムは色々なコンポーネントの組み合わせで成り立っているところで動く
     * システム毎に特性などが違う
* そのため単一のベンチマークでの比較は難しい
     * （汎用性があるため）様々な箇所で稼働することになり現実的なワークロードを反映するのも難しい
* この論文ではファイルシステム・ストレージシステムの106件の論文をサーベイした結果を述べる。
     * オーバーヘッドを隠蔽していたり、逆に大げさに強調しているようなものもみられる。
* 多くのベンチマークには欠点があり、システムの真の性能を発揮して比較できていないことを述べる。
     * 特筆すべき例として「slowing down read operations on ext2 by a factor of 32 resulted in only a 2–5% wall-clock slowdown in a popular compile benchmark」とあるがこの段階では何が言いたいのか良くわからない。
* とりあえずこの論文ではベンチマークをする上で今後どうするべきかを論じたい。

先に ext2 のどうこういう例が何なのかだけ確認する（もうちょっと良い文章を書いてほしい……）
12.2節でこの話が書かれている。compiler benchmarkという類のベンチマークに関して、ファイルシステムのreadのレイテンシ時間を
`2^5=32`倍遅くした（これをやるためにslowfsというものを作っている）場合とそうでない場合とで合計の実行時間に殆ど差がないことから、
ベンチマークの殆どの時間はCPUを使った計算に費やされていると結論付けているものである。

これぐらいならtimeコマンドのreal timeとcpu timeの引き算で気づけそうなものだが、それで気づけないかどうかぐらいは書いていると思うので、
とりあえず読み進める。

# 1. 序論
* ベンチマークの重要さを訥々と語っている
* この論文ではベンチマークセットの「選び方」または「作り方」に焦点をあてる
* ベンチマークを3種類に分類した
      * マクロベンチマーク: 現実のワークロードを使ったベンチマーク 7章で扱う
      * トレース再現（trace replays): 操作をreplayするらしいがこの段階では良くわからない 8章で扱う
      * マイクロベンチマーク: 数個の操作に絞って操作毎の細かなパフォーマンスをみるためのベンチマーク 9章で扱う

# 2. サーベイした論文について
SOSP, OSDI, FAST, USENIXが良い論文を通しているだろうということで、この中から選んだという話。
サーベイした論文については、この論文のReferencesにそれと分かるようにアスタリスク付きで書いている。

# 3. システムをベンチする時に考慮した方が良いこと
ものすごく簡単に言うと何をベンチマークとして実施したのかということや、選択肢のある中なら何故そうしたのかということをちゃんと書きましょうという話。

## 3.1 <system, configuration, benchmark type>
* system
     * いわゆる実験に使うマシンの持つspec
* configuration
     * うーんちょっと書きづらいからもう少し定義しようという姿勢が欲しい
