# ファイルシステムのベンチマークを行う際に注意することとは?
という視点で次の論文を読みます:
https://www.fsl.cs.sunysb.edu/docs/fsbench/fsbench.pdf

# 0. 概要
* ファイルシステムやストレージシステムのベンチマークによる比較は難しい 
     * システムは色々なコンポーネントの組み合わせで成り立っているところで動く
     * システム毎に特性などが違う
* そのため単一のベンチマークでの比較は難しい
     * （汎用性があるため）様々な箇所で稼働することになり現実的なワークロードを反映するのも難しい
* この論文ではファイルシステム・ストレージシステムの106件の論文をサーベイした結果を述べる。
     * オーバーヘッドを隠蔽していたり、逆に大げさに強調しているようなものもみられる。
* 多くのベンチマークには欠点があり、システムの真の性能を発揮して比較できていないことを述べる。
     * 特筆すべき例として「slowing down read operations on ext2 by a factor of 32 resulted in only a 2–5% wall-clock slowdown in a popular compile benchmark」とあるがこの段階では何が言いたいのか良くわからない。
* とりあえずこの論文ではベンチマークをする上で今後どうするべきかを論じたい。

先に ext2 のどうこういう例が何なのかだけ確認する（もうちょっと良い文章を書いてほしい……）
12.2節でこの話が書かれている。compiler benchmarkという類のベンチマークに関して、ファイルシステムのreadのレイテンシ時間を
`2^5=32`倍遅くした（これをやるためにslowfsというものを作っている）場合とそうでない場合とで合計の実行時間に殆ど差がないことから、
ベンチマークの殆どの時間はCPUを使った計算に費やされていると結論付けているものである。

これぐらいならtimeコマンドのreal timeとcpu timeの引き算で気づけそうなものだが、それで気づけないかどうかぐらいは書いていると思うので、
とりあえず読み進める。

# 1. 序論
* ベンチマークの重要さを訥々と語っている
* この論文ではベンチマークセットの「選び方」または「作り方」に焦点をあてる
* ベンチマークを3種類に分類した
      * マクロベンチマーク: 現実のワークロードを使ったベンチマーク 7章で扱う
      * トレース再現（trace replays): 操作をreplayするらしいがこの段階では良くわからない 8章で扱う
      * マイクロベンチマーク: 数個の操作に絞って操作毎の細かなパフォーマンスをみるためのベンチマーク 9章で扱う

# 2. サーベイした論文について
SOSP, OSDI, FAST, USENIXが良い論文を通しているだろうということで、この中から選んだという話。
サーベイした論文については、この論文のReferencesにそれと分かるようにアスタリスク付きで書いている。

# 3. システムをベンチする時に考慮した方が良いこと
ものすごく簡単に言うと何をベンチマークとして実施したのかということや、選択肢のある中なら何故そうしたのかということをちゃんと書きましょうという話。

## 3.1 パフォーマンス比較の重要な三要素 <system, configuration, benchmark type>
* system
     * いわゆる実験に使うマシンとかソフトウェアとか
* configuration
     * systemを決めた後に変更可能な要素で、ベンチマーク対象が直接的に持つ mode とか parameter とかこの辺だと思う
     * 直接的という表現にしているのは、3.2 で考えるenvironmentと区別したいから（これはyuezatoが勝手に足した表現)
* benchmark type     
     * Macrobenchmark: 複数の命令を使ってsystemの全体的な性能を測る
     * Microbenchmark: １つか２つの命令に絞って個別または局所的な性能を測る
     * Trace-based: いまいち雰囲気がつかめない [あとでかきなおす]
     * どのベンチマークでも大事なことは次の5つだと考えている
           * CPUとIOのどっちがどれぐらい絡んでくるか・割合が明らか
           * ベンチマーク自身が時間計測をする場合はそれが正確なものであること（測定すると予告していることを正しく測っているという意味においてだと思う）
           * スケールすること; 性能に関して謎の頭打ちなどが生じることなく、ハードウェアやソフトウェアが進歩しても絶えず使えるようなもの
           * マルチスレッド; ことファイルシステムは普通マルチスレッドなプログラムで使役されるので、現実的な用途も調べられなくてはならない
           * 理解可能なものでありかつ再現可能であること

## 3.2 Choosing The Benchmarking Environment
systemというかmachineかも知れないが、ベンチマークに影響を及ぼす様々な環境について考慮しなくてはならない。
少なくともresultはどの環境で行われたベンチマークのresultかという環境とのセットでも提出される必要がある。
環境というのは
* キャッシュの状態（CPUキャッシュに限らずファイルシステムのキャシュとかも諸々）
        * キャッシュが効く（warm)にしたければ連続して走らせて外れ値を捨てたりするとか
        * キャッシュが効かない(cold)にしたければ逐一でrebootしろとか
        * そういうことが書いてます
* HDDなどのZCAVのon/off
        * 最近のHDDは、内周よりも外周の面積のほうが大きい分だけセクタサイズが増え、外周では1セクタ間の移動時間が短くなり云々という話がある
        * これを極力抑えたければ`[Ellard and Seltzer 2003b]`のような工夫もできるが、現実的ではないので、この論文ではpartitionの位置を明記して再現性を出す程度で留める
* File Systemのaging（fragmentationの度合いとか)
        * 現実に近い環境を作るならファイルシステムをマウントして「長い時間をかけて」agingを行うべきだが、本当に長い時間がかかるのでagingは大変である
        * 大変だが考慮するべき
        * Agingに関してはFAST'19でこういう論文があったので一読 https://www.usenix.org/conference/hotstorage19/presentation/conway
* ベンチマーク中に動いている他のプロセスの有無（現実的なシステムでは他のプロセスも動いてるのでそこも考えなくてはならない)
        * 現実的には他のプロセスも動かしたいが再現性などが薄れてしまう
        * 代わりにベンチマークをマルチスレッド化すれば現実味は出てくるだろう [いまいち意味が分からないので後で書き直す]
        
## 3.3 Running the Benchmarks
以下が大事
* 比較環境で同一のrunが行われること
* 十分に多い回数実験すること
* 各runは十分に長い時間であること
* 人手だとミスするのでautomationすること 11章で述べる
     * やったと主張している通りのベンチマークが実はできていなくて正しい結果が出ていないということがよくあるので賢くなれよという話だと思う
     
## 3.4 結果を記す時には
* 標準偏差よりも信頼区間をもとにした方が良い
     * The standard deviation is a measure of the amount of variation between runs. 
     * The half-width of the confidence interval describes how far the true value may be from the captured mean with a given degree of confidence (e.g., 95%)
     *  as more benchmark runs are performed, the standard deviation may not decrease, but the width of confidence intervals generally will.
* For experiments with fewer than 30 runs, one should be careful not to use
the normal distribution for calculating confidence intervals. This is because
the central-limit theorem no longer holds with a small sample size. Instead,
one should use the student’s t-distribution. This distribution may also be used
